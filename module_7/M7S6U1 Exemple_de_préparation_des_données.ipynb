{"cells":[{"cell_type":"markdown","metadata":{"id":"KVYNOn_WW3Iw"},"source":["---\n","# Module 7.1: Exemple de préparation des données\n","---\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1b8bP5Nm76jwDnXXikW4XyYrC_pthzcCD  width=\"400\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: https://www.futura-sciences.com/sante/dossiers/medecine-tout-savoir-diabete-859/page/2/</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","\n","Dans ce script en Python, nous allons montrer les étapes nécessaires à la préparation des données provenant d'une base de données réelles, colligée à partir d'informations sur des sujets atteints du diabète. Les données seront par la suite utilisées dans un autre tutoriel du cours afin d'expliquer la méthode systématique permettant d'optimiser un classificateur/régresseur, ou plusieurs en même temps.\n","\n","La base de données contient des données disparates (taux de glucose dans le sang, indice de masse corporelle, épaisseur de la peau, etc.). C'est souvent le cas dans la pratique où l'on mesure un grand nombre de variables qu'on souhaite utiliser pour prédire une réponse d'intérêt, dans ce cas-ci, prédire si une personne est atteinte ou non du diabète.\n","\n","### Informations sur la base de données.\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1XNkAdr-Tjz7aK7FGrZljdJ79YmAvCgN9  width=\"400\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: Google Image/</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","La base de données [diabetes](https://www.kaggle.com/uciml/pima-indians-diabetes-database) contient neuf variables, continues ou ordinales, qui ont été mesurées chez 768 sujets:\n","\n","<ul>\n","<li><b>Pregnancies</b>: nombre de grossesses,</li>\n","<li><b>Glucose</b>: taux de glucose,</li>\n","<li><b>BloodPressure</b>: pression artérielle,</li>\n","<li><b>SkinThickness</b>: épaisseur de la peau,</li>\n","<li><b>Insulin</b>: taux d'insuline,</li>\n","<li><b>BMI</b>: indice de masse corporelle (IMC), </li>\n","<li><b>DiabetesPedigreeFunction</b>: facteur de diabète,</li>\n","<li><b>Age</b>: âge,</li>\n","<li><b>Outcome</b>: résultat.</li>\n","</ul>\n","\n","La dernière, Outcome, contient la réponse binaire que l'on veut prédire. Une personne est atteinte \n","du diabète lorsque *Outcome*=1. Comme pour bien des bases de données, celle-ci contient plusieurs valeurs manquantes (<i>missing values</i>) et possiblement plusieurs valeurs aberrantes (<i>outliers</i>). Nous allons voir comment la nettoyer.\n","\n","\n","### Étapes de traitement des données\n","Dans ce qui suit, nous allons effectuer les étapes suivantes :\n","<ul>\n","<li>le traitement des valeurs manquantes,</li>\n","<li>le traitement des valeurs aberrantes,</li>\n","<li>la transformation des variables,</li>\n","<li>l'élimination des variables fortement corrélées.</li>\n","</ul>\n","\n","Toutes les données du jeu de données seront utilisées pour effectuer cette analyse exploratoire. \n","\n","\n","### IMPORTANT: Copie du notebook!\n","\n","Vous devez faire une copie du notebook dans votre drive avant de l'exécuter, car les modifications dans le notebook original ne seront pas sauvegardées. Vous travaillerez ainsi dans la copie et non dans l'original.\n","\n","\n","Importation des fichiers à utiliser dans le tutoriel."]},{"cell_type":"code","source":["%%bash\n","git clone https://github.com/Cours-EDUlib/IVADO-AA.git\n","mv IVADO-AA/module_7/* ./\n","rm -r IVADO-AA"],"metadata":{"id":"fJPpeA2eRv-p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677703430988,"user_tz":300,"elapsed":7797,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}},"outputId":"23200b0c-c12e-47f3-8ca3-9c5dc8595332"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["Cloning into 'IVADO-AA'...\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LE6MrskVW3I0","executionInfo":{"status":"ok","timestamp":1677703435657,"user_tz":300,"elapsed":4673,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["%%capture\n","import sklearn\n","from sklearn.model_selection import cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import IsolationForest\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.impute import KNNImputer\n","from sklearn.preprocessing import StandardScaler, QuantileTransformer\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set(color_codes=True)\n","\n","%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Pour la reproductibilité des résultats\n","np.random.seed(43)\n","\n","# Author: Pierre Gravel <pierre.gravel@iid.ulaval.ca>\n","# License: BSD"]},{"cell_type":"markdown","metadata":{"id":"83dCFOYvW3I2"},"source":["## Partie I: Traitement des valeurs manquantes\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1fQ--2jboAXWpyoEiws4-DKX6UFBujd-2  width=\"300\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: https://www.flickr.com/photos/78830297@N05/14556250857/</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","\n","### Identification des valeurs manquantes\n","\n","#### Lecture des données: \n","\n","Les données sont écrites dans un dataframe de la librairie Pandas."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LkO_pAIoW3I3","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"error","timestamp":1677703435911,"user_tz":300,"elapsed":257,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}},"outputId":"e5149950-d489-4fac-c700-65085f769b3c"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-bd32d810057f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"]}],"source":["df = pd.read_csv('diabetes.csv')"]},{"cell_type":"markdown","metadata":{"id":"N1bmMcG6W3I3"},"source":["Les valeurs manquantes dans les bases de données sont souvent indiquées par  NaN (<i>not a number</i>) \n","ou par des zéros. \n","\n","#### Affichage du nombre de valeurs manquantes NaN dans le dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1CgA65HW3I4","executionInfo":{"status":"aborted","timestamp":1677703435912,"user_tz":300,"elapsed":8,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"TIFuHxZXW3I4"},"source":["Il n'y a aucune valeur de type NaN pour les variables mesurées.\n","\n","#### Affichage des valeurs minimales pour chaque variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01sW7uT8W3I4","executionInfo":{"status":"aborted","timestamp":1677703435912,"user_tz":300,"elapsed":7,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df.min()"]},{"cell_type":"markdown","metadata":{"id":"zp0ZI39FW3I5"},"source":["Plusieurs variables ont une valeur minimale nulle. Seules les variables *Outcome* et *Pregnancies* peuvent avoir des valeurs nulles. Les autres valeurs nulles indiquent la présence de valeurs manquantes. \n","\n","#### Remplacement des valeurs manquantes, indiquées par des zéros, avec des NaN.\n","\n","En remplaçant les valeurs nulles par des NaN, nous pourrons utiliser les fonctions d'imputation de variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s28jPX4bW3I5","executionInfo":{"status":"aborted","timestamp":1677703435913,"user_tz":300,"elapsed":8,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["features = df.drop(['Outcome', 'Pregnancies'], axis=1).columns.to_list()\n","\n","for col in features:\n","    df.loc[df[df[col] == 0].index, col] = np.nan"]},{"cell_type":"markdown","metadata":{"id":"XuaoK24KW3I6"},"source":["#### Affichage du nombre de valeurs manquantes de type NaN dans le dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sKNsFhzW3I6","executionInfo":{"status":"aborted","timestamp":1677703435913,"user_tz":300,"elapsed":8,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["def na_summary(df):\n","    return df.isnull().sum()\n","\n","na_summary(df)"]},{"cell_type":"markdown","metadata":{"id":"47b9LPPqW3I6"},"source":["Il y a des valeurs manquantes pour cinq variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vpqqsfCW3I7","executionInfo":{"status":"aborted","timestamp":1677703435913,"user_tz":300,"elapsed":8,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']"]},{"cell_type":"markdown","metadata":{"id":"h5FGmhtTW3I7"},"source":["L'affichage des 5 premières lignes de la base de données révèle quelques valeurs manquantes NaN."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LS1q-DVbW3I7","executionInfo":{"status":"aborted","timestamp":1677703435914,"user_tz":300,"elapsed":13555,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"wJT2ATAVW3I7"},"source":["### Imputation des valeurs manquantes\n","\n","Nous allons examiner plusieurs méthodes d'imputation afin de choisir la meilleure. Dans chaque cas, le jeu de données \n","modifié sera classifié avec une forêt aléatoire. La meilleure méthode d'imputation sera celle pour laquelle \n","l'exactitude en classification sera supérieure. Le type de classificateur n'est pas très important ici, en autant qu'il soit performant.\n","\n","Séparation des noms de variables en entrées X et en sortie Y."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PV3gBlPgW3I8","executionInfo":{"status":"aborted","timestamp":1677703435914,"user_tz":300,"elapsed":13553,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["Xcol = df.drop(['Outcome'], axis=1).columns.to_list()\n","Ycol = 'Outcome'"]},{"cell_type":"markdown","metadata":{"id":"0hV1UbRyW3I8"},"source":["Spécification du classificateur par forêt aléatoire (*Random Forest*, ou RF)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfqsFfTvW3I8","executionInfo":{"status":"aborted","timestamp":1677703435915,"user_tz":300,"elapsed":13553,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["rf = RandomForestClassifier()"]},{"cell_type":"markdown","metadata":{"id":"sdS1KQivW3I8"},"source":["#### Méthode I: Suppression simple des données manquantes\n","\n","C'est la méthode la plus souvent utilisée lors d'un premier essai de traitement des données."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yYrPFkUW3I8","executionInfo":{"status":"aborted","timestamp":1677703435915,"user_tz":300,"elapsed":13547,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df_elimine = df.copy(deep=True)\n","\n","# Suppression des données manquantes\n","df_elimine = df_elimine.dropna()\n","\n","\n","Xel = df_elimine[Xcol]\n","Yel = df_elimine[Ycol]\n","\n","# Entraînement du classificateur\n","elimine_score = cross_val_score(rf, Xel, Yel, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[ÉLIMINATION] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xel), 100*elimine_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"GxnI7ysRW3I9"},"source":["#### Méthode II: Substitution par la médiane\n","\n","Afin de ne pas perdre inutilement des données, on ne laisse plus tomber les valeurs manquantes. On\n","les remplace par la médiane des valeurs connues.\n","\n","N.B. Il faut traiter séparément les valeurs des sujets sains (*Outcome*=0) et diabétiques (*Outcome*=1). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRd5_F_0W3I9","executionInfo":{"status":"aborted","timestamp":1677703436151,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["# Fonction assignant la médiane des valeurs connues de la variable var aux valeurs manquantes de la même variable\n","def assigne_mediane(df_mediane, var):   \n","    for i in range(2):\n","        # Indices des sujets avec valeurs présentes\n","        indx1 = (df_mediane['Outcome'] == i ) & (df_mediane[var].notnull())\n","        \n","        # Indices des sujets avec valeurs manquantes\n","        indx2 = (df_mediane['Outcome'] == i ) & (df_mediane[var].isnull())\n","        \n","        # Subsitution avec la médiane des valeurs présentes\n","        df_mediane.loc[indx2, var] = df_mediane.loc[indx1, var].median()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ppSqjBaW3I9","executionInfo":{"status":"aborted","timestamp":1677703436151,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df_mediane = df.copy(deep=True)\n","\n","# Substitution par la médiane\n","for var in features:\n","    assigne_mediane(df_mediane, var)\n","\n","\n","Xmediane = df_mediane[Xcol]\n","Ymediane = df_mediane[Ycol]\n","\n","# Entraînement du classificateur\n","mediane_score = cross_val_score(rf, Xmediane, Ymediane, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[MÉDIANE] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xmediane), 100*mediane_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"kLZU_xWvW3I9"},"source":["#### Méthode III: MICE\n","\n","La méthode MICE (<i>Multiple Imputation by Chained Equations</i>) est une méthode d'imputation itérative."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEVYanB_W3I-","executionInfo":{"status":"aborted","timestamp":1677703436151,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df_mice = df.copy(deep=True)\n","\n","# Substitution par la méthode MICE\n","df_mice[Xcol] = IterativeImputer().fit_transform(df_mice[Xcol])\n","\n","\n","Xmice = df_mice[Xcol]\n","Ymice = df_mice[Ycol]\n","\n","# Entraînement du classificateur\n","mice_score = cross_val_score(rf, Xmice, Ymice, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[MICE] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xmice), 100*mice_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"3hBOHRQrW3I-"},"source":["#### Méthode IV: K-NN\n","\n","\n","Nous allons maintenant utiliser le classificateur des N plus proches voisins afin de trouver, pour chaque sujet partiellement connu, les sujets entièrement connus les plus près dans l'espace des variables X.\n","\n","On assigne au sujet partiellement connu la moyenne des variables inconnues, calculées à partir de ses N plus proches voisins.\n","\n","N.B. Il faut normaliser les variables afin de mesurer les distances entre les données.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZSxSWP_W3I-","executionInfo":{"status":"aborted","timestamp":1677703436151,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df_knn = df.copy(deep=True)\n","\n","Xknn = df_knn[Xcol]\n","Yknn = df_knn[Ycol]\n","\n","# Normalisation des données\n","Xnorm = StandardScaler().fit_transform(Xknn)\n","\n","kvals = np.arange(10, 110, 10, dtype='int64')\n","\n","# On essaie différents nombres de plus proches voisins afin de trouver la valeur optimale\n","scores = []\n","for k in kvals:\n","    Xknn = KNNImputer(n_neighbors=k, missing_values=np.nan).fit_transform(Xnorm)\n","    \n","    # Entraînement du classificateur\n","    score = cross_val_score(rf, Xknn, Yknn, cv=5, n_jobs=2).mean()\n","\n","    scores.append(score)\n","    print(\n","        \"[K-NN] Estimation RF (n = %d, k = %d, CV à 5 plis): %2.1f %%\" % (\n","            len(Xknn), k, 100*score)\n","    )"]},{"cell_type":"markdown","metadata":{"id":"ee7_FC06W3I-"},"source":["Déterminons le nombre $N_{optimal}$ de voisins."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRPn-rKqW3I-","executionInfo":{"status":"aborted","timestamp":1677703436152,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["sns.set_style(\"darkgrid\")\n","_ = plt.plot(kvals, scores)\n","_ = plt.xlabel('K')\n","_ = plt.ylabel('Exactitude')\n","\n","knn_score = max(scores)\n","k_opt = kvals[scores.index(knn_score)]\n","\n","knn = KNNImputer(n_neighbors=k_opt, missing_values=np.nan)\n","Xknn = knn.fit_transform(Xnorm)\n","\n","df_knn[Xcol] = Xknn\n","\n","print(\n","    \"[Meilleur K-NN] Estimation RF (n = %d, k opt = %d, CV à 5 plis): %2.1f %%\" % (\n","        len(Xknn), k_opt, 100*knn_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"HL8WivseW3I_"},"source":["#### Comparons maintenant les résultats des multiples méthodes d'imputation testées."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0GWKMlYuW3I_","executionInfo":{"status":"aborted","timestamp":1677703436152,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["errs = {\n","    'K-NN': knn_score,\n","    'MICE': mice_score,\n","    'MÉDIANE': mediane_score,\n","    'ÉLIMINATION': elimine_score,\n","}\n","\n","err_df = pd.DataFrame.from_dict(errs, orient='index')\n","err_df.reset_index(inplace=True)\n","err_df.columns = ['Imputation', 'Score']\n","\n","ax = sns.barplot(\n","    x=err_df.columns[1],\n","    y=err_df.columns[0],\n","    order=err_df.sort_values('Score', ascending=False).Imputation,\n","    data=err_df,\n",")\n","ax.set_ylabel('')\n","ax.set_xlabel('Estimation sur Test  (CV à 10 plis)')\n","_ = plt.xlim(0.7, 0.9)"]},{"cell_type":"markdown","metadata":{"id":"xw6T6BzwW3I_"},"source":["### Que faut-il comprendre de ce graphique ?\n","\n","Si on complète les données manquantes avec divers modèles, on peut améliorer le pouvoir de\n","prédiction (en ajoutant un biais dans les données).\n","\n","Notez à quel point la simple élimination des données manquantes, bien qu'intuitive, n'est \n","pas efficace. En creusant un peu plus, on est passés d'un score d'environ 79 % à 88 % juste en remplaçant les valeurs manquantes par les valeurs médianes correspondantes. Appelons la valeur obtenue avec la médiane, la valeur de base (*baseline*).\n","\n","Notez également que les méthodes complexes d'imputation ne sont pas toujours les meilleures. C'est du cas par cas, en fonction du jeu de données à traiter. Dans cet exemple, il manque tellement de valeurs des variables *SkinThickness* et *Insulin* que les méthodes d'interpolation MICE et KNN performent mal.\n"," \n","Les quatres méthodes d'imputation sont souvent utilisées ensemble pour trouver la meilleure à utiliser par la suite.\n","\n","Pour le reste de ce script, nous allons utiliser les valeurs imputées au moyen de la méthode de la médiane.\n","\n","## Partie II: Le traitement des valeurs aberrantes\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1zCMpsltZ--jYZlbcb14xTGekx93s-NN4  width=\"300\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: https://beyondrecognition.net/insights-from-outliers//</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","\n","On peut détecter la présence de variables aberrantes (*outliers*) dans un jeu de données en utilisant des diagrammes en boîtes à moustaches (*box plots*), mais nous allons plutôt utiliser les distributions conjointes des variables.\n","\n","#### Affichage des distributions conjointes des variables numériques\n","\n","Ce type de diagramme met en valeur les corrélations multiples entre les variables ainsi que les valeurs aberrantes. Cette opération est un peu longue à effectuer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pzkRok73W3I_","executionInfo":{"status":"aborted","timestamp":1677703436152,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df2 = df_mediane.copy(deep=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eyauJXzW3I_","executionInfo":{"status":"aborted","timestamp":1677703436152,"user_tz":300,"elapsed":4,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["sns.pairplot(df2, hue='Outcome')"]},{"cell_type":"markdown","metadata":{"id":"TL4-OtyFW3JA"},"source":["Les pics observables dans les valeurs de *SkinThickness* et *Insulin* sont dus au remplacement d'un grand nombre de valeurs manquantes pour ces deux variables.\n","\n","Bien que ces pics semblent artificiels dans les nuages de données, il faut se rappeler que l'ajout de données par imputation améliore les performances en classification.\n","\n","On remarque que plusieurs variables sont fortement corrélées entre elles; ex. *SkinThickness* et *BMI*. Ce n'est pas surprenant puisque les gens en surpoids ont un indice de masse corporel (BMI) et une épaisseur de peau plus élevés. \n","\n","On remarque également que les sujets diabétiques (en orange) ont des niveaux plus élevés de chaque caractéristique. Les points oranges sont déplacés vers la droite dans chaque panneau. \n","\n","Les bornes supérieures des histogrammes le long de la diagonale principale sont très étendues pour plusieurs variables. Cela révèle souvent la présence de valeurs aberrantes.\n","\n","### Comment traiter les valeurs aberrantes?\n","\n","Dans ce qui suit, on va supposer, pour l'exemple, \n","que la base de données contient jusqu'à 5 % de valeurs aberrantes de toutes sortes. Ça représente $0,05*768 \\approx 38$ valeurs.\n","\n","On utilise la méthode de la [forêt d'isolation](https://scikitlearn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) pour détecter un maximum de 5 % des valeurs possiblement aberrantes. \n","\n","N.B. La méthode IsolationForest mesure la distance entre les différents points dans l'espace des variables d'entrée. Comme on a vu précédemment, celles-ci varient sur différents ordres de grandeur. Il faut donc les normaliser. Cette normalisation est utilisée uniquement pour identifier les données avec des valeurs aberrantes. On retourne ensuite aux variables non normalisées."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNpN1CivW3JA","executionInfo":{"status":"aborted","timestamp":1677703436153,"user_tz":300,"elapsed":5,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["def elimine_valeurs_aberrantes(data, contamination):\n","    df3 = data.copy(deep=True)\n","    \n","    # Noms des variables d'entrée\n","    Xcol = df3.drop(['Outcome'], axis=1).columns.to_list()\n","    \n","    # Normalisation des variables d'entrées\n","    scaler = StandardScaler()\n","    df3[Xcol] = scaler.fit_transform(df3[Xcol])\n","\n","    # Détection des valeurs aberrantes. Cette fonction ajoute une variable outliers \n","    # dans le dataframe. La variable outliers vaut -1 pour les valeurs aberrantes \n","    # et +1 pour les autres\n","    i_forest = IsolationForest(contamination=contamination)\n","    df3['outliers'] = i_forest.fit(df3[Xcol]).predict(df3[Xcol])\n","    \n","    # Élimination des valeurs aberrantes des données originales. \n","    # On conserve ainsi les variables originales, sans normalisation.\n","    data.drop(df3[df3.outliers < 0].index, inplace = True)\n","    \n","    return data"]},{"cell_type":"markdown","metadata":{"id":"aOkB1LnEW3JA"},"source":["#### Élimination des valeurs aberrantes.\n","\n","Cette opération est un peu longue à effectuer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6_TxNvaW3JA","executionInfo":{"status":"aborted","timestamp":1677703436153,"user_tz":300,"elapsed":5,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["n_avant = df2.shape[0]\n","df2 = elimine_valeurs_aberrantes(df2, 0.05)\n","\n","n_apres = df2.shape[0]\n","\n","print('Nombre de valeurs aberrantes éliminées : %d' % (n_avant-n_apres))"]},{"cell_type":"markdown","metadata":{"id":"rNw_0PPgW3JA"},"source":["Appliquons le même classificateur par forêt aléatoire que précédemment afin de voir si l'exactitude a été améliorée \n","en retirant 5 % des valeurs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46UKBUZTW3JB","executionInfo":{"status":"aborted","timestamp":1677703436153,"user_tz":300,"elapsed":13749,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["X = df2[Xcol]\n","Y = df2[Ycol]\n","\n","# Entraînement du classificateur\n","mediane2_score = cross_val_score(rf, X, Y, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[MÉDIANE] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xcol), 100*mediane2_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"tCbbPNPsW3JB"},"source":["Les performances de classification sont similaires à la *baseline*. N.B. Si on retire trop de données, on retire aussi les cas les plus difficiles à classifier! Il est normal alors que les performances s'améliorent dans ce cas. \n","\n","Affichons à nouveau les distributions conjointes des variables. Cette opération est un peu longue à effectuer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbFY85t_W3JB","executionInfo":{"status":"aborted","timestamp":1677703436154,"user_tz":300,"elapsed":13744,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["sns.pairplot(df2, hue='Outcome')"]},{"cell_type":"markdown","metadata":{"id":"rMp47Ek2W3JB"},"source":["Les nuages de points sont plus compacts et les valeurs aberrantes ont disparues. Notez que les lignes horizontales et verticales causées par l'imputation des données pour les données de SkinThickness et Insulin sont encore plus visibles maintenant."]},{"cell_type":"markdown","metadata":{"id":"16E2yl5PW3JB"},"source":["**EXERCICE:**\n","\n","Montrez comment les performances du classificateur changent lorsque le taux de contamination varie entre 1% et 50%. Comment interprétez vous ces résultats? Quelles conclusions en tirez-vous?"]},{"cell_type":"markdown","metadata":{"id":"d17jOzyoW3JB"},"source":["## Partie III: Transformation des variables\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1aKbVIsFEdmiSIkSXt4SCTXt48FogCS-N  width=\"400\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: https://webstockreview.net/explore/lab-clipart-chemical-reaction/</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","\n","Affichons les histogrammes des variables corrigées avec la méthode médiane."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOeTTRmzW3JC","executionInfo":{"status":"aborted","timestamp":1677703436154,"user_tz":300,"elapsed":13743,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df2 = df_mediane.copy(deep=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ucoHLCx5W3JC","executionInfo":{"status":"aborted","timestamp":1677703436154,"user_tz":300,"elapsed":13739,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["feature_cols = df2.columns.to_list()\n","\n","fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 6))\n","plt.tight_layout()\n","\n","for col, ax in zip(feature_cols, axes.flatten()):\n","    sns.histplot(data=df2, x=col, ax=ax, bins=20, kde=True)"]},{"cell_type":"markdown","metadata":{"id":"3tkKltaSW3JC"},"source":["On remarque que les variables *SkinThickness*, *Insulin* et *BMI* ressemblent à des gaussiennes. Transformons-les en gaussiennes en utilisant la transformation par quantile."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xoyh1Jq7W3JC","executionInfo":{"status":"aborted","timestamp":1677703436154,"user_tz":300,"elapsed":13737,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["features = ['SkinThickness', 'Insulin', 'BMI']\n","\n","for col in features:\n","    X = df2[col]\n","    X = np.array(X).reshape(-1, 1)    \n","    X = QuantileTransformer(output_distribution='normal').fit_transform(X)\n","    df2[col] = X"]},{"cell_type":"markdown","metadata":{"id":"XxQAF2mEW3JC"},"source":["Affichons à nouveau les histogrammes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0uCaBs5W3JC","executionInfo":{"status":"aborted","timestamp":1677703436155,"user_tz":300,"elapsed":13734,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["feature_cols = df2.columns.to_list()\n","\n","fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(10, 6))\n","plt.tight_layout()\n","\n","for col, ax in zip(feature_cols, axes.flatten()):\n","    sns.histplot(data=df2, x=col, ax=ax, bins=20, kde=True)"]},{"cell_type":"markdown","metadata":{"id":"ijUFvIgMW3JC"},"source":["Les nouveaux histogrammes pour les variables *SkinThickness*, *Insulin* et *BMI* sont des distributions plus gaussiennes qu'auparavant.\n","\n","Appliquons le même classificateur que précédemment afin de voir si l'exactitude a été améliorée en transformant ces variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bJw4wZWXW3JD","executionInfo":{"status":"aborted","timestamp":1677703436155,"user_tz":300,"elapsed":13730,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["X = df2[Xcol]\n","Y = df2[Ycol]\n","\n","mediane2_score = cross_val_score(rf, X, Y, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[MÉDIANE] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xcol), 100*mediane2_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"cZmYKDZMW3JD"},"source":["Les performances de classification sont similaires à la valeur de base."]},{"cell_type":"markdown","metadata":{"id":"Nbkt3IzzW3JD"},"source":["## Partie IV: Élimination de variables fortement corrélées entre elles"]},{"cell_type":"markdown","metadata":{"id":"o4XF-QDLW3JD"},"source":["Il arrive souvent qu'un jeu de données contiennent des variables X fortement corrélées entre elles. Plusieurs \n","types de classificateurs sont affectées par ce problème, mais d'autres le sont moins, sinon pas du tout.\n","\n","Voici un exemple typique de variables corrélées: le nombre d'items similaires achetés est proportionnel au prix payé pour l'ensemble des items. Les deux variables sont parfaitement corrélées; la première peut être déterminée à partir de la seconde. On peut laisser tomber l'une des deux.\n","\n","Examinons la matrice de corrélation des variables.\n","\n","On utilise la valeurs corrigées avec la méthode médiane."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGlcvyXPW3JD","executionInfo":{"status":"aborted","timestamp":1677703436155,"user_tz":300,"elapsed":13729,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df2 = df_mediane.copy(deep=True)"]},{"cell_type":"markdown","metadata":{"id":"pchGnuGSW3JD"},"source":["#### Calcul de la matrice de corrélation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KSPug0ZW3JD","executionInfo":{"status":"aborted","timestamp":1677703436156,"user_tz":300,"elapsed":13729,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["corr = df2.corr()"]},{"cell_type":"markdown","metadata":{"id":"SvymlP3cW3JD"},"source":["#### Affichage des résultats avec la réponse *Outcome* en tête et les variables en ordre décroissant de corrélation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77hXxLZzW3JE","executionInfo":{"status":"aborted","timestamp":1677703436156,"user_tz":300,"elapsed":13725,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["nvar = len(df2.columns)\n","\n","plt.figure(figsize=(10, 7))\n","cols = corr.nlargest(nvar, 'Outcome')['Outcome'].index\n","cm = np.corrcoef(df2[cols].values.T)\n","sns.set(font_scale=1.25)\n","hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', \n","                 annot_kws={'size': 14}, yticklabels=cols.values, \n","                 xticklabels=cols.values, cmap=\"viridis\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"eEVvPyqfW3JE"},"source":["Examinons les termes sous la diagonale en jaune. Les termes au-dessus ont les mêmes valeurs puisqu'une \n","matrice de corrélation est symétrique. \n","\n","On peut faire les observations suivantes:\n","<ul>\n","<li>les corrélations significatives sont positives; les variables augmentent avec les autres,</li>\n","<li>le nombre de grossesses augmente avec l'âge,</li>\n","<li>le taux de glucose augmente avec le taux d'insuline dans le sang,</li>\n","<li>l'indice de masse corporelle augmente avec l'épaisseur de la peau,</li>\n","<li>le taux de glucose a le plus grand effet sur la probabilité d'être diabétique.</li>\n","</ul>\n","\n","Une analyse plus approfondie nous permettra de mieux discerner les effets de chaque variable X sur la probabilité d'être diabétique. L'importance des variables choisies par un classificateur pour prédire la variable Outcome nous donne des indices. \n","\n","Mis à part sur la diagonale, il n'y a pas de corrélations supérieures à 60%. On n'a pas besoin d'éliminer des variables fortement corrélées avec d'autres.\n","\n","### Comment réduire l'effet des données corrélées ?\n","\n","Supposons, pour l'exemple, que l'on décide d'éliminer la corrélation entre les variables *BMI* et *SkinThickness*. Il suffit d'enlever une des deux de la base de données.\n","\n","Enlevons la variable *SkinThickness*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wte6bRfW3JE","executionInfo":{"status":"aborted","timestamp":1677703436157,"user_tz":300,"elapsed":13725,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["df2 = df2.drop(['SkinThickness'], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"0fTQvtzDW3JE"},"source":["Appliquons le même classificateur par forêt aléatoire que précédemment afin de voir si l'exactitude a été améliorée \n","en retirant cette variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bn2jzK4fW3JE","executionInfo":{"status":"aborted","timestamp":1677703436157,"user_tz":300,"elapsed":13721,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["# Attention, le nombre de variables en X a changé!\n","Xcol2 = df2.drop(['Outcome'], axis=1).columns.to_list()\n","Ycol2 = 'Outcome'\n","\n","X = df2[Xcol2]\n","Y = df2[Ycol2]\n","\n","mediane2_score = cross_val_score(rf, X, Y, cv=5, n_jobs=2).mean()\n","\n","print(\n","    \"[MÉDIANE] Estimation RF (n = %d, CV à 5 plis): %2.1f %%\" \n","    % (len(Xcol), 100*mediane2_score)\n",")"]},{"cell_type":"markdown","metadata":{"id":"YlKYPbw-W3JE"},"source":["Encore une fois, les performances de classification sont similaires à la valeur de base (*baseline*).\n","\n","## Partie V: Sauvegarde des données traitées.\n","\n","<p>&nbsp;</p>\n","<div align=\"center\">\n","    <img src= https://drive.google.com/uc?id=1h7gCmIWlmFCJrzH9HgwCCa84WWKPM1Dk  width=\"400\" />\n","    <div>\n","    <font size=\"1.5\">Image Source: https://medium.com/swlh/data-cleaning-with-pandas-e9796d1ff9c9/</font>\n","    </div>\n","</div>\n","<p>&nbsp;</p>\n","\n","Dans ce script, on a testé séparément différentes méthodes de prétraitement des données :\n","<ul>\n","<li>le traitement des valeurs manquantes,</li>\n","<li>le traitement des valeurs aberrantes,</li>\n","<li>la transformation des variables,</li>\n","<li>l'élimination des variables fortement corrélées.</li>\n","</ul>\n","\n","Seule l'étape de traitement des valeurs manquantes a montré une amélioration des performances du classificateur par forêt aléatoire. Les autres étapes ont eu des effets négligeables. \n","\n","Toutes les données du jeu de données ont été utilisées pour effectuer cette analyse exploratoire. Nous allons maintenant nettoyer la base de données et la sauvegarder afin de pouvoir l'utiliser dans le tutoriel sur la sélection et l'optimisation d'un modèle optimal. \n","\n","#### Prétraitement et sauvegarde des données"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZRRVW5hW3JE","executionInfo":{"status":"aborted","timestamp":1677703436157,"user_tz":300,"elapsed":13719,"user":{"displayName":"Pierre Gravel","userId":"08025702416652476882"}}},"outputs":[],"source":["# Lecture des données\n","df = pd.read_csv('diabetes.csv')\n","\n","# Remplacement des valeurs manquantes, indiquées par des zéros, avec des NaN.\n","features = df.drop(['Outcome', 'Pregnancies'], axis=1).columns.to_list()\n","\n","for col in features:\n","    df.loc[df[df[col] == 0].index, col] = np.nan\n","    \n","# Imputation des valeurs manquantes avec la médiane\n","features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n","\n","for var in features:\n","    assigne_mediane(df, var)\n","    \n","# Sauvegarde des données corrigées\n","df.to_csv('diabetes_nettoyee.csv', index = False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}